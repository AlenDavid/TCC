\section{Calculating Code Complexity}

In this section we cover the classes and numeric values observed in this work.
First, lets introduce the tool we will be using to collect them.
\cite{article:mozilla} will be used in this paper to collect the differences between
before and after of each refactor implementation.

\subsection{Cyclomatic Complexity}

A common model used by companies to describe Complexity is McCabe's Cyclomatic Complexity.
This metric is determined by counting the number of decision points, such as if statements,
loops, and case conditions, and adding one to represent the single entry-exit path.
A higher cyclomatic complexity indicates more intricate and potentially error-prone code,
which can be harder to test, maintain, and understand.

\begin{itemize}
  \item Sum \begin{description}
          \item the overall complexity of every code block across the source files.
        \end{description}
  \item Min \begin{description}
          \item the smallest value found for a method.
        \end{description}
  \item Max \begin{description}
          \item the largest value found for a method.
        \end{description}
  \item Average \begin{description}
          \item averaging the sum of every method by the number of methods in the system.
        \end{description}
\end{itemize}


\subsection{Cognitive Complexity}

An alternative to Cyclomatic Complexity, \cite{article:sonarpaper} describes as the new way of calculating complexity of code,
pointing that Cyclomatic Complexity is old as it doesn't acknowledge newer code structures like try/catch blocks and lambdas.

Similar items as Cyclomatic Complexity.

\begin{itemize}
  \item Sum \begin{description}
          \item the overall complexity of every code block across the source files.
        \end{description}
  \item Min \begin{description}
          \item the smallest value found for a method.
        \end{description}
  \item Max \begin{description}
          \item the largest value found for a method.
        \end{description}
  \item Average \begin{description}
          \item averaging the sum of every method by the number of methods in the system.
        \end{description}
\end{itemize}

\subsection{Halstead Metrics}

In literature, its common to see the use of Halstead measurements to describe complexity
\cite{article:complexity_with_halstead}.
Maurice Halstead, in 1977, created a set of quantitative rules that calculates the effort to understand target software,
number of bugs expected in the program, average time that is taken to implement the program.
To do so, it first measures the distinct and total operators and operands the program has and uses these four base
measures as information to understand the software as a whole.

The variables used in Halstead metrics starts with $n_{1}$, representing the number of distinct operators and $n_{2}$ the
number of distinct operands. Then we calculate the total occurrences of both variables across the software code, calculating
$N_{1}$ as the total occurrence of distinct operators and $N_{2}$ for distinct operands.

The volume (\(V\)) of a program quantifies the size of its implementation as \(N \times \log_2(n)\). Difficulty (\(D\)) reflects the effort needed to understand the program, calculated as \(\frac{n_1}{2} \times \frac{N_2}{n_2}\). The program level (\(L\)) is the inverse of difficulty, indicating how close the program is to optimal implementation.

Effort (\(E\)), which equals \(D \times V\), represents the cognitive workload required to write the program. The estimated program length (\(H\)) offers an approximation of the program's ideal length using logarithms of the operator and operand counts. The time required to develop the program (\(T\)) is given by \(E \div 18\), and the number of delivered bugs (\(B\)) is estimated as \(E^{\frac{2}{3}} \div 3000\). Finally, the purity ratio (\(PR\)), defined as \(H \div N\), measures how well-structured the program is relative to its actual length.

\subsection{Lines of Code}

This class measures each and every line from the source code, splitting them into different metrics.
This class contains the following metrics: source lines ($SLOC$); comment lines ($CLOC$); physical lines ($PLOC = SLOC + CLOC$);
logical lines ($LLOC$), the count of statements; and blank lines ($BLANK$) representing empty lines.

\subsection{Maintainability Index}

This high level metric can be found in code editors (like Visual Studio), giving developers a score to say how well maintain
a source code is. It takes in account source lines of code, Cyclomatic Complexity and Halstead metrics's Volume to calculate its Index value.

The Original Maintainability Index (\(MI_O\)) is a formula used to assess software maintainability.
It combines the program's volume (\(V\)), cyclomatic complexity (\(CC\)), and source lines of code (\(SLOC\)) to provide a score.
The formula is \(171 - 5.2 \times \ln(V) - 0.23 \times CC - 16.2 \times \ln(SLOC)\).

The Maintainability Index by the Software Engineering Institute (\(MI_{SEI}\)) builds on the original formula by
adding a factor that accounts for the ratio of commented lines of code (\(CLOC\)) to total source lines of code (\(SLOC\)).
This addition emphasizes the impact of documentation on maintainability.
The formula is \(171 - 5.2 \times \ln(V) - 0.23 \times CC - 16.2 \times \ln(SLOC) + 50 \times \sin(\sqrt{2.4 \times \frac{CLOC}{SLOC}})\).

The Maintainability Index implemented in Visual Studio (\(MI_{VS}\)) modifies \(MI_O\) to scale the value
between 0 and 100 for a more interpretable range.
It is calculated as \(\max(0, MI_O \times \frac{100}{171})\).

\subsection{Number of methods, exits and arguments}

For data flow, we quantify the occurrence of methods, functions, closures, exits and arguments the program have.

\begin{itemize}
  \item Number of Methods \begin{description}
          \item Counts the occurrence of functions or closures. \begin{description}
                  \item[Functions] quantity of functions observed in source code.
                  \item[Closures] the quantity of closures observed in source code.
                  \item[Total] The sum of functions and closures.
                \end{description}
        \end{description}

  \item Number of Exits \begin{description}
          \item Counts the occurrence of exits in methods. \begin{description}
                  \item[Sum] The total occurrence of exits found.
                  \item[Average] The total occurrence of exits divided by total of methods.
                  \item[Min] The smallest value found for $NEXITS$ across methods.
                  \item[Max] The opposite, this one is the maximum value found.
                \end{description}
        \end{description}

  \item Number of Arguments \begin{description}
          \item Counts the occurrence of exits in methods. \begin{description}
                  \item[Sum] The total occurrence of arguments found.
                  \item[Average] The total occurrence of arguments divided by total of methods.
                  \item[Min] The smallest value found for $NARGS$ across methods.
                  \item[Max] The opposite, this one is the maximum value found.
                \end{description}
        \end{description}
\end{itemize}
